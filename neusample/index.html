
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>NeuSample</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jaminfong.cn/neusample"/>
    <meta property="og:title" content="NeuSample" />
    <meta property="og:description" content="Project page for NeuSample: Neural Sample Field for Efficient View Synthesis." />

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>NeuSample</b>: Neural Sample Field for </br> Efficient View Synthesis</br> 
                <!-- <small>
                </small> -->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://jaminfong.cn/">
                            Jiemin Fang
                        </a>
                        </br>HUST
                    </li>
                    <li>
                        <a href="http://lingxixie.com/">
                            Lingxi Xie
                        </a>
                        </br>Huawei
                    </li>
                    <li>
                        <a href="https://xinggangw.info/">
                            Xinggang Wang
                        </a><sup>✉</sup>
                        </br>HUST
                    </li><br>
                    <li>
                        <a href="https://sites.google.com/site/zxphistory/">
                            Xiaopeng Zhang
                        </a>
                        </br>Huawei
                    </li>
                    <li>
                        <a href="http://eic.hust.edu.cn/professor/liuwenyu/">
                            Wenyu Liu
                        </a>
                        </br>HUST
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?hl=en&user=61b6eYkAAAAJ">
                            Qi Tian
                        </a>
                        </br>Huawei
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2111.15552">
                            <image src="img/paper.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/hustvl/NeuSample">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p align="center">
                    <image width="70%" src="img/method_comp.png" class="img-responsive" alt="overview">
                </p>
                <p class="text-justify">
                Neural radiance fields (NeRF) have shown great potentials in representing 3D scenes and synthesizing novel views, but the computational overhead of NeRF at the inference stage is still heavy. To alleviate the burden, we delve into the coarse-to-fine, hierarchical sampling procedure of NeRF and point out that the coarse stage can be replaced by a lightweight module which we name a neural sample field. The proposed sample field maps rays into sample distributions, which can be transformed into point coordinates and fed into radiance fields for volume rendering. The overall framework is named as NeuSample. We perform experiments on Realistic Synthetic 360° and Real Forward-Facing, two popular 3D scene sets, and show that NeuSample achieves better rendering quality than NeRF while enjoying a faster inference speed. NeuSample is further compressed with a proposed sample field extraction method towards a better trade-off between quality and speed.
                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <video id="v0" width="100%" autoplay loop muted controls>
                        <source src="img/NeuSample-video.mp4" type="video/mp4" />
                      </video>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Sample Field
                </h3>
                <p class="text-justify">
                    We propose a neural sample field which maps a ray directly into a series of samples for volume rendering.
                </p>
                <p align="center">
                    <image src="img/field_eq1.jpg" class="img-responsive" width="33%"><br>
                </p>
                <p class="text-justify">
                    Specifically, we first obtain N scalars, which lie in 0 and 1, by feeding ray origin coordinates and direction into the sample field. The output scalar represents the relative sample position between the near and far bound along the ray. Then these scalars are transformed into absolute coordinates.
                <image src="img/field_eq2.jpg" class="img-responsive"><br>
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Integrating Sample Fields with Radiance Fields
                </h3>
                <image src="img/framework.png" class="img-responsive"><br>
                <p class="text-justify">
                To render a pixel in the image, the ray passing through the pixel is first fed into a sample field network, which is mapped to a distribution along the ray. The distribution is then transformed to 3D-point coordinates, which are fed into the radiance field to obtain colors and densities. Finally, volume rendering is performed on these points.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Sample Field Extraction
                </h3>
                <p align="center">
                    <image src="img/extraction.png" class="img-responsive" width="80%">
                </p>
                <p class="text-justify">
                Besides saving computation cost from coarse fields, we extract the learned sample field to produce fewer samples for further acceleration. A depth boost method is proposed for initializing an extracted field. The output mean value of the extracted field is forced to fit the depth predicted by a learned regular field.
                </p>
            </div>
        </div>
            


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <p class="text-justify">
                    We evaluate NeuSample on both Realistic Synthetic 360° and Real Forward-Facing scenes, which shows competitive or better rendering quality with less computation cost than NeRF.
                </p>
                <br>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/lego.mp4" type="video/mp4" />
                </video>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/ship.mp4" type="video/mp4" />
                </video>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/horns.mp4" type="video/mp4" />
                </video>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/trex.mp4" type="video/mp4" />
                </video>
                <br><br>
                <p class="text-justify">
                    Under different acceleration settings, NeuSample shows a much better speed-quality trade-off.
                </p>
                <image src="img/trade-off.png" class="img-responsive"><br>
            </div>
        </div>

            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{fang2021neusample,
    title={NeuSample: Neural Sample Field for Efficient View Synthesis},
    author={Jiemin Fang and Lingxi Xie and Xinggang Wang and Xiaopeng Zhang and Wenyu Liu and Qi Tian},
    journal={arXiv:2111.15552},
    year={2021}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                We would like to thank <a href="https://lsongx.github.io/">Liangchen Song</a>, Yingqing Rao and <a href="https://scholar.google.com/citations?user=EGewoUAAAAAJ">Yuzhu Sun</a> for their generous assistance and discussion. <br>

                The website template was borrowed from <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
